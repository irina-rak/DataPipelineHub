{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "from os import scandir\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/splitted_dataset/val/COVID\n",
      "../datasets/splitted_dataset/val/Lung_Opacity\n",
      "../datasets/splitted_dataset/val/Normal\n",
      "../datasets/splitted_dataset/val/Viral Pneumonia\n"
     ]
    }
   ],
   "source": [
    "_set = \"val\"\n",
    "\n",
    "dataset_dir = f\"../datasets/splitted_dataset/{_set}\"\n",
    "\n",
    "for entry in scandir(dataset_dir):\n",
    "    if entry.is_dir():\n",
    "        print(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(columns=[\"Image Index\", \"Finding Labels\", \"Path\"])\n",
    "\n",
    "for entry in scandir(dataset_dir):\n",
    "    if entry.is_dir():\n",
    "        label = entry.name\n",
    "        img_list = [img for img in scandir(entry.path) if img.is_file() and img.name.endswith(\".png\")]\n",
    "        data_df = pd.concat(\n",
    "            [\n",
    "                data_df,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"Image Index\": [img.name for img in img_list],\n",
    "                        \"Finding Labels\": label,\n",
    "                        # \"Path\": [entry.path.removeprefix(f\"../datasets/splitted_dataset/{_set}/\") for img in img_list],\n",
    "                        \"Path\": [entry.path.replace(f\"../datasets/splitted_dataset/{_set}\", \"COVID-19_Radiography_Dataset\") for img in img_list],\n",
    "                    }\n",
    "                ),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Transforms the labels into one-hot encoded labels.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        data (pd.DataFrame): Dataframe containing the labels.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        pd.DataFrame: Dataframe with one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    data_df = df.copy()\n",
    "    labels = (\n",
    "        pd.get_dummies(df[\"Finding Labels\"].str.split(\"|\").explode())\n",
    "        .groupby(level=0)\n",
    "        .sum()\n",
    "    )\n",
    "    data_df = pd.concat([data_df, labels], axis=1)\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def stratified_train_test_split(\n",
    "    df_file: Union[str, pd.DataFrame]\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split the data into train, validation, and test sets\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        file_path (str): Path to the csv file or the DataFrame containing the data\n",
    "    \"\"\"\n",
    "    if isinstance(df_file, str):\n",
    "        df = pd.read_csv(df_file)\n",
    "    else:\n",
    "        df = df_file.copy()\n",
    "\n",
    "    # Create 5 splits and merge the 4 splits to create the training set and the last split to create the test set\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    train_df = None\n",
    "    val_df = None\n",
    "    for train_index, test_index in sss.split(df, df[\"Finding Labels\"]):\n",
    "        train_df = df.iloc[train_index]\n",
    "        val_df = df.iloc[test_index]\n",
    "\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_dummy_labels(data_df)\n",
    "\n",
    "data_df.to_csv(f\"../datasets/csv_splits/COVID-19_Radiography_Dataset_{_set}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_dummy_labels(data_df)\n",
    "\n",
    "train_df, test_df = stratified_train_test_split(data_df)\n",
    "train_df, val_df = stratified_train_test_split(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"datasets/csv_splits/COVID-19_Radiography_Dataset_train.csv\", index=False)\n",
    "# val_df.to_csv(\"datasets/csv_splits/COVID-19_Radiography_Dataset_val.csv\", index=False)\n",
    "# test_df.to_csv(\"datasets/csv_splits/COVID-19_Radiography_Dataset_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "_img_names = train_df[\"Image Index\"].values\n",
    "_paths = train_df[\"Path\"].values\n",
    "# _data_df = torch.tensor(data_df.drop(columns=[\"Finding Labels\", \"Path\"]).values)\n",
    "# data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data_df = data_df.drop(columns=[\"Image Index\", \"Finding Labels\", \"Path\"]).values\n",
    "_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
