{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import scandir\n",
    "from os.path import join\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils.utils import plot_disease_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df_path = \"../datasets/csv_splits/COVID-19_Radiography_Dataset_train.csv\"\n",
    "val_data_df_path = \"../datasets/csv_splits/COVID-19_Radiography_Dataset_val.csv\"\n",
    "\n",
    "train_data_df = pd.read_csv(train_data_df_path)\n",
    "val_data_df = pd.read_csv(val_data_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Path</th>\n",
       "      <th>COVID</th>\n",
       "      <th>Lung_Opacity</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Viral Pneumonia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-1.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-1000.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-1001.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-1002.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-1004.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Image Index Finding Labels                                Path  COVID  \\\n",
       "0     COVID-1.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "1  COVID-1000.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "2  COVID-1001.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "3  COVID-1002.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "4  COVID-1004.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "\n",
       "   Lung_Opacity  Normal  Viral Pneumonia  \n",
       "0             0       0                0  \n",
       "1             0       0                0  \n",
       "2             0       0                0  \n",
       "3             0       0                0  \n",
       "4             0       0                0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirichlet_split(k: int, n: int) -> np.ndarray:\n",
    "    \"\"\"Get a random split of size `n` into `k` parts using a Dirichlet distribution.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        k (int): Number of parts to split the elements into (clients).\n",
    "        n (int): Number of elements to split (total number of images).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        np.ndarray: Array containing the split sizes.\n",
    "    \"\"\"\n",
    "    # rng = np.random.default_rng(seed)\n",
    "    split_sizes = np.random.dirichlet(np.ones(k), size=1)[0]\n",
    "\n",
    "    # Scale the split sizes to the number of elements adjust the last split size to make sure the sum is equal to n\n",
    "    split_sizes = np.round(split_sizes * n).astype(int)\n",
    "    split_sizes[-1] = n - split_sizes[:-1].sum()\n",
    "    return split_sizes\n",
    "\n",
    "\n",
    "def get_split(n_splits: int, unbalanced: bool, class_distribution: dict) -> np.ndarray:\n",
    "    \"\"\"Get the split sizes for the clients.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        n_splits (int): Number of clients to split the data into.\n",
    "        unbalanced (bool): Whether to split the data into unbalanced clients.\n",
    "        class_distribution (dict): Dictionary containing the class names and their counts.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        np.ndarray: Array containing the split sizes.\n",
    "    \"\"\"\n",
    "    if unbalanced:\n",
    "        split_sizes = {cls: 0 for cls in class_distribution.keys()}\n",
    "        for cls in class_distribution.keys():\n",
    "            split_sizes[cls] = get_dirichlet_split(n_splits, class_distribution[cls])\n",
    "    else:\n",
    "        split_sizes = {cls: np.full(n_splits, class_distribution[cls] // n_splits) for cls in class_distribution.keys()}\n",
    "        for cls in class_distribution.keys():\n",
    "            split_sizes[cls][:class_distribution[cls] % n_splits] += 1\n",
    "\n",
    "    return split_sizes\n",
    "\n",
    "\n",
    "def split_targets(reamaining_clients: list, removed_images: dict, df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Split the removed images into the remaining clients.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        reamaining_clients (list): List of clients to assign the removed images to.\n",
    "        removed_images (dict): Dictionary containing the removed images for each client.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        dict: Dictionary containing the split images for each client.\n",
    "    \"\"\"\n",
    "    splits = {idx: {} for idx in removed_images.keys()}\n",
    "    for idx, imgs in removed_images.items():\n",
    "        # for client in reamaining_clients:\n",
    "        #     if imgs.size > 0:\n",
    "        classes = df[df[\"Image Index\"].isin(imgs)][\"Finding Labels\"].str.split(\"|\").explode().unique()\n",
    "        # Split classes into n remaining clients\n",
    "        for cls in classes:\n",
    "            filtered = df[df[\"Image Index\"].isin(imgs)]\n",
    "            filtered = filtered[filtered[\"Finding Labels\"].str.contains(cls)]\n",
    "            split_sizes = get_split(len(reamaining_clients), len(filtered), False)\n",
    "            split_clients = np.split(filtered[\"Image Index\"].values, np.cumsum(split_sizes)[:-1])\n",
    "            for i, client in enumerate(reamaining_clients):\n",
    "                # splits[client].extend(split_clients[i])\n",
    "                splits[idx][client] = split_clients[i]\n",
    "                \n",
    "    return splits\n",
    "\n",
    "\n",
    "def get_class_distribution(df: pd.DataFrame) -> Dict[str, int]:\n",
    "    \"\"\"Get the class distribution of the dataset.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        df (pd.DataFrame): DataFrame containing the data with \"Finding Labels\".\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        Dict[str, int]: Dictionary containing the class distribution.\n",
    "    \"\"\"\n",
    "    class_distribution = df[\"Finding Labels\"].str.split(\"|\").explode().value_counts().to_dict()\n",
    "    return class_distribution\n",
    "\n",
    "\n",
    "def random_fl_split(\n",
    "    n_splits: int,\n",
    "    df: pd.DataFrame,\n",
    "    unbalanced: bool = False,\n",
    "    extreme: bool = False,\n",
    "    # target_clients: Union[List[int], int] = None,\n",
    "    # target_classes: Union[List[str], str] = None,\n",
    "    target_classes: Dict[int, List[str]] = None,\n",
    "    seed: int = 42,\n",
    ") -> Tuple[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits the dataset into `n_splits` clients using random assignment with optional unbalancing.\n",
    "\n",
    "    Args:\n",
    "        n_splits (int): Number of clients to split the data into.\n",
    "        df (pd.DataFrame): DataFrame containing the data with \"Image Index\" and \"Finding Labels\".\n",
    "        unbalanced (bool): If True, creates unbalanced splits.\n",
    "        extreme (bool): If True, applies extreme unbalancing based on `target_clients` and `target_classes`.\n",
    "        target_classes (Dict[int, List[str]]): Dictionary containing the target classes to be removed from each client.\n",
    "        seed (int): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame]: Tuple containing the DataFrames for each client.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # images = df[\"Image Index\"].unique()\n",
    "    # np.random.shuffle(images)\n",
    "\n",
    "    # assert 0 < n_splits <= len(images), \"n_splits must be between 1 and the number of unique images.\"\n",
    "    assert len(target_classes) < len(df[\"Finding Labels\"].unique()), \"Number of target classes must be less than the available number of classes.\"\n",
    "    \n",
    "    # if isinstance(target_clients, int):\n",
    "    #     target_clients = [target_clients]\n",
    "    if isinstance(target_classes, str):\n",
    "        target_classes = [target_classes]\n",
    "\n",
    "    # Generate split sizes\n",
    "    # if unbalanced:\n",
    "    #     random_points = np.sort(np.random.choice(len(images) - 1, n_splits - 1, replace=False))\n",
    "    #     split_sizes = np.diff([0] + random_points.tolist() + [len(images)])\n",
    "    # else:\n",
    "    #     split_sizes = np.full(n_splits, len(images) // n_splits)\n",
    "    #     split_sizes[:len(images) % n_splits] += 1\n",
    "    \n",
    "    print(f\"Unbalanced: {unbalanced}\")\n",
    "    cls_dist = get_class_distribution(df)\n",
    "    split_sizes = get_split(n_splits, unbalanced, class_distribution=cls_dist)\n",
    "    # print(f\"Split sizes: {split_sizes}\")\n",
    "\n",
    "    # clients = np.split(images, np.cumsum(split_sizes)[:-1])\n",
    "    clients = {idx: [] for idx in range(n_splits)}\n",
    "    for cls, sizes in split_sizes.items():\n",
    "        images = df[df[\"Finding Labels\"].str.contains(cls)][\"Image Index\"].values\n",
    "        for i, size in enumerate(sizes):\n",
    "            clients[i].extend(np.random.choice(images, size, replace=False))\n",
    "            # choices = np.setdiff1d(images, clients[i])\n",
    "            images = np.setdiff1d(images, clients[i])\n",
    "\n",
    "    if extreme and target_classes:\n",
    "        target_clients = list(target_classes.keys())\n",
    "        to_swap = {idx: [] for idx in target_clients}\n",
    "    #     for idx in target_clients:\n",
    "    #         filtered = df[df[\"Image Index\"].isin(clients[idx])]\n",
    "    #         filtered = filtered[filtered[\"Finding Labels\"].str.contains(\"|\".join(target_classes[idx]))]\n",
    "    #         to_swap[idx] = filtered[\"Image Index\"].values\n",
    "\n",
    "    #     remaining_clients = [client for client in range(n_splits) if client not in target_clients]\n",
    "\n",
    "    #     removed_images = split_targets(remaining_clients, to_swap, df)\n",
    "\n",
    "    #     for idx, splits in removed_images.items():\n",
    "    #         for client, split in splits.items():\n",
    "    #             clients[client] = np.concatenate([clients[client], split])\n",
    "    #             clients[idx] = np.setdiff1d(clients[idx], split)\n",
    "\n",
    "    # client_dfs = [df[df[\"Image Index\"].isin(client)].reset_index(drop=True) for client in clients]\n",
    "    # client_dfs = {idx: df[df[\"Image Index\"].isin(client)].reset_index(drop=True) for idx, client in clients.items()}\n",
    "    client_dfs = [df[df[\"Image Index\"].isin(client)].reset_index(drop=True) for client in clients.values()]\n",
    "\n",
    "    return tuple(client_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2336 5093  856 7397  120  332  141  655]\n"
     ]
    }
   ],
   "source": [
    "# _split = get_dirichlet_split(5, len(train_data_df), 4)\n",
    "_split = get_dirichlet_split(8, len(train_data_df))\n",
    "print(_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Normal': array([1020, 1019, 1019, 1019, 1019, 1019, 1019, 1019]), 'Lung_Opacity': array([602, 601, 601, 601, 601, 601, 601, 601]), 'COVID': array([362, 362, 362, 362, 361, 361, 361, 361]), 'Viral Pneumonia': array([135, 135, 135, 135, 134, 134, 134, 134])}\n"
     ]
    }
   ],
   "source": [
    "_cls_dist = get_class_distribution(train_data_df)\n",
    "_split_sizes = get_split(8, False, _cls_dist)\n",
    "\n",
    "print(_split_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced: True\n"
     ]
    }
   ],
   "source": [
    "n_clients = 8\n",
    "\n",
    "target_classes = {\n",
    "    # 1: [\"COVID\", \"Lung_Opacity\"],\n",
    "    # 2: [\"Normal\"]\n",
    "    1: [\"COVID\"],\n",
    "}\n",
    "\n",
    "# Seeds:\n",
    "# 2: 1651\n",
    "# 4: ....\n",
    "# 8: \n",
    "\n",
    "client_dfs = random_fl_split(n_clients, train_data_df, unbalanced=True, extreme=False, target_classes=target_classes, seed=1651)\n",
    "# client_dfs = random_fl_split(n_clients, val_data_df, unbalanced=False, extreme=False, target_classes=target_classes, seed=1651)\n",
    "# remaining_clients, to_swap = random_fl_split(4, train_data_df, unbalanced=True, extreme=True, target_classes=target_classes, seed=1651)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, cl_df in enumerate(client_dfs):\n",
    "    cl_df.to_csv(f\"../datasets/csv_splits/{n_clients}_clients/unbalanced_all_classes/CXR_covid_train_client_{idx + 1}.csv\", index=False)\n",
    "    # cl_df.to_csv(f\"../datasets/csv_splits/{n_clients}_clients/CXR_covid_val_client_{idx + 1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection between client 0 and client 1: 0\n",
      "Intersection between client 0 and client 2: 0\n",
      "Intersection between client 0 and client 3: 0\n",
      "Intersection between client 0 and client 4: 0\n",
      "Intersection between client 0 and client 5: 0\n",
      "Intersection between client 0 and client 6: 0\n",
      "Intersection between client 0 and client 7: 0\n",
      "Intersection between client 1 and client 2: 0\n",
      "Intersection between client 1 and client 3: 0\n",
      "Intersection between client 1 and client 4: 0\n",
      "Intersection between client 1 and client 5: 0\n",
      "Intersection between client 1 and client 6: 0\n",
      "Intersection between client 1 and client 7: 0\n",
      "Intersection between client 2 and client 3: 0\n",
      "Intersection between client 2 and client 4: 0\n",
      "Intersection between client 2 and client 5: 0\n",
      "Intersection between client 2 and client 6: 0\n",
      "Intersection between client 2 and client 7: 0\n",
      "Intersection between client 3 and client 4: 0\n",
      "Intersection between client 3 and client 5: 0\n",
      "Intersection between client 3 and client 6: 0\n",
      "Intersection between client 3 and client 7: 0\n",
      "Intersection between client 4 and client 5: 0\n",
      "Intersection between client 4 and client 6: 0\n",
      "Intersection between client 4 and client 7: 0\n",
      "Intersection between client 5 and client 6: 0\n",
      "Intersection between client 5 and client 7: 0\n",
      "Intersection between client 6 and client 7: 0\n"
     ]
    }
   ],
   "source": [
    "# Intersecting images\n",
    "# len(set(client_dfs[2][\"Image Index\"].unique()).intersection(set(client_dfs[1][\"Image Index\"].unique())))\n",
    "\n",
    "# Check intersection between clients\n",
    "for i in range(n_clients):\n",
    "    for j in range(i + 1, n_clients):\n",
    "        print(f\"Intersection between client {i} and client {j}: {len(set(client_dfs[i]['Image Index'].unique()).intersection(set(client_dfs[j]['Image Index'].unique())))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
