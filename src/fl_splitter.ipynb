{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs, scandir\n",
    "from os.path import isdir, join\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils.utils import plot_disease_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df_path = \"../datasets/csv_splits/COVID-19_Radiography_Dataset_train.csv\"\n",
    "val_data_df_path = \"../datasets/csv_splits/COVID-19_Radiography_Dataset_val.csv\"\n",
    "\n",
    "train_data_df = pd.read_csv(train_data_df_path)\n",
    "val_data_df = pd.read_csv(val_data_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Path</th>\n",
       "      <th>COVID</th>\n",
       "      <th>Lung_Opacity</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Viral Pneumonia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-1.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-1000.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-1001.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-1002.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-1004.png</td>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-19_Radiography_Dataset/COVID</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Image Index Finding Labels                                Path  COVID  \\\n",
       "0     COVID-1.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "1  COVID-1000.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "2  COVID-1001.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "3  COVID-1002.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "4  COVID-1004.png          COVID  COVID-19_Radiography_Dataset/COVID      1   \n",
       "\n",
       "   Lung_Opacity  Normal  Viral Pneumonia  \n",
       "0             0       0                0  \n",
       "1             0       0                0  \n",
       "2             0       0                0  \n",
       "3             0       0                0  \n",
       "4             0       0                0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dirichlet_split(k: int, n: int) -> np.ndarray:\n",
    "    \"\"\"Get a random split of size `n` into `k` parts using a Dirichlet distribution.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        k (int): Number of parts to split the elements into (clients).\n",
    "        n (int): Number of elements to split (total number of images).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        np.ndarray: Array containing the split sizes.\n",
    "    \"\"\"\n",
    "    split_sizes = np.random.dirichlet(np.ones(k), size=1)[0]\n",
    "\n",
    "    # Scale the split sizes to the number of elements adjust the last split size to make sure the sum is equal to n\n",
    "    split_sizes = np.round(split_sizes * n).astype(int)\n",
    "    split_sizes[-1] = n - split_sizes[:-1].sum()\n",
    "    return split_sizes\n",
    "\n",
    "\n",
    "def get_split(n_splits: int, unbalanced: bool, class_distribution: dict) -> np.ndarray:\n",
    "    \"\"\"Get the split sizes for the clients.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        n_splits (int): Number of clients to split the data into.\n",
    "        unbalanced (bool): Whether to split the data into unbalanced clients.\n",
    "        class_distribution (dict): Dictionary containing the class names and their counts.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        np.ndarray: Array containing the split sizes.\n",
    "    \"\"\"\n",
    "    if unbalanced:\n",
    "        split_sizes = {cls: 0 for cls in class_distribution.keys()}\n",
    "        for cls in class_distribution.keys():\n",
    "            split_sizes[cls] = get_dirichlet_split(n_splits, class_distribution[cls])\n",
    "    else:\n",
    "        split_sizes = {cls: np.full(n_splits, class_distribution[cls] // n_splits) for cls in class_distribution.keys()}\n",
    "        for cls in class_distribution.keys():\n",
    "            split_sizes[cls][:class_distribution[cls] % n_splits] += 1\n",
    "\n",
    "    return split_sizes\n",
    "\n",
    "\n",
    "def split_targets(reamaining_clients: list, removed_images: dict, df: pd.DataFrame) -> dict:\n",
    "    \"\"\"Split the removed images into the remaining clients.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        reamaining_clients (list): List of clients to assign the removed images to.\n",
    "        removed_images (dict): Dictionary containing the removed images for each client.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        dict: Dictionary containing the split images for each client.\n",
    "    \"\"\"\n",
    "    splits = {idx: {} for idx in removed_images.keys()}\n",
    "    for idx, imgs in removed_images.items():\n",
    "        classes = df[df[\"Image Index\"].isin(imgs)][\"Finding Labels\"].str.split(\"|\").explode().unique()\n",
    "\n",
    "        # Split classes into n remaining clients\n",
    "        for cls in classes:\n",
    "            filtered = df[df[\"Image Index\"].isin(imgs)]\n",
    "            filtered = filtered[filtered[\"Finding Labels\"].str.contains(cls)]\n",
    "            split_sizes = get_split(len(reamaining_clients), len(filtered), False)\n",
    "            split_clients = np.split(filtered[\"Image Index\"].values, np.cumsum(split_sizes)[:-1])\n",
    "\n",
    "            for i, client in enumerate(reamaining_clients):\n",
    "                splits[idx][client] = split_clients[i]\n",
    "                \n",
    "    return splits\n",
    "\n",
    "\n",
    "def get_class_distribution(df: pd.DataFrame) -> Dict[str, int]:\n",
    "    \"\"\"Get the class distribution of the dataset.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        df (pd.DataFrame): DataFrame containing the data with \"Finding Labels\".\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        Dict[str, int]: Dictionary containing the class distribution.\n",
    "    \"\"\"\n",
    "    class_distribution = df[\"Finding Labels\"].str.split(\"|\").explode().value_counts().to_dict()\n",
    "    return class_distribution\n",
    "\n",
    "\n",
    "def random_fl_split(\n",
    "    n_splits: int,\n",
    "    df: pd.DataFrame,\n",
    "    unbalanced: bool = False,\n",
    "    target_classes: Dict[int, Dict[int, List[str]]] = None,\n",
    "    seed: int = 42,\n",
    ") -> Tuple[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits the dataset into `n_splits` clients using random assignment with optional unbalancing.\n",
    "\n",
    "    Args:\n",
    "        n_splits (int): Number of clients to split the data into.\n",
    "        df (pd.DataFrame): DataFrame containing the data with \"Image Index\" and \"Finding Labels\".\n",
    "        unbalanced (bool): If True, creates unbalanced splits.\n",
    "        extreme (bool): If True, applies extreme unbalancing based on `target_clients` and `target_classes`.\n",
    "        target_classes (Dict[int, Dict[int, List[str]]]): Dictionary containing the target classes to be removed from each client.\n",
    "        seed (int): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame]: Tuple containing the DataFrames for each client.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    if isinstance(target_classes, str):\n",
    "        target_classes = [target_classes]\n",
    "    \n",
    "    cls_dist = get_class_distribution(df)\n",
    "    split_sizes = get_split(n_splits, unbalanced, class_distribution=cls_dist)\n",
    "    \n",
    "    clients = {idx + 1: [] for idx in range(n_splits)}\n",
    "    for cls, sizes in split_sizes.items():\n",
    "        images = df[df[\"Finding Labels\"].str.contains(cls)][\"Image Index\"].values\n",
    "        for i, size in enumerate(sizes):\n",
    "            clients[i + 1].extend(np.random.choice(images, size, replace=False))\n",
    "            images = np.setdiff1d(images, clients[i + 1])\n",
    "\n",
    "    if target_classes:\n",
    "        for target_client, origin_clients in target_classes.items():\n",
    "            for origin_client, classes in origin_clients.items():\n",
    "                for cls in classes:\n",
    "                    filtered = filter(lambda x: cls in x, clients[origin_client])\n",
    "                    imgs = [img for img in filtered]\n",
    "                    clients[target_client].extend(imgs)\n",
    "                    clients[origin_client] = np.setdiff1d(clients[origin_client], imgs).tolist()\n",
    "                    \n",
    "    client_dfs = [df[df[\"Image Index\"].isin(client)].reset_index(drop=True) for client in clients.values()]\n",
    "\n",
    "    return tuple(client_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced: True\n"
     ]
    }
   ],
   "source": [
    "n_clients = 2\n",
    "\n",
    "target_classes = {\n",
    "    1: {\n",
    "        2: [\"COVID\", \"Viral Pneumonia\"],\n",
    "        3: [\"COVID\"],\n",
    "        4: [\"COVID\"],\n",
    "    },\n",
    "    2: {\n",
    "        3: [\"Lung_Opacity\"],\n",
    "        4: [\"Lung_Opacity\"],\n",
    "    },\n",
    "    3: {\n",
    "        2: [\"Normal\"],\n",
    "        4: [\"Normal\"],\n",
    "    },\n",
    "    4: {\n",
    "        # 2: [\"Viral Pneumonia\"],\n",
    "        3: [\"Viral Pneumonia\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Seeds: 42, 1651\n",
    "\n",
    "client_dfs = random_fl_split(n_clients, train_data_df, unbalanced=True, target_classes=target_classes, seed=864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Finding Labels\n",
       "COVID              2892\n",
       "Normal             1378\n",
       "Lung_Opacity        241\n",
       "Viral Pneumonia     116\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_dfs[0][\"Finding Labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Finding Labels\n",
       "Lung_Opacity    4568\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_dfs[1][\"Finding Labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, cl_df in enumerate(client_dfs):\n",
    "    save_dir = f\"../datasets/csv_splits/{n_clients}_clients/unbalanced_missing_classes/one_per_client_except_1\"\n",
    "    if not isdir(save_dir):\n",
    "        print(f\"Creating directory: {save_dir}\")\n",
    "        makedirs(save_dir)\n",
    "\n",
    "    cl_df.to_csv(f\"{save_dir}/CXR_covid_train_client_{idx + 1}.csv\", index=False)\n",
    "    # cl_df.to_csv(f\"../datasets/csv_splits/{n_clients}_clients/CXR_covid_val_client_{idx + 1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection between client 0 and client 1: 0\n",
      "Intersection between client 0 and client 2: 0\n",
      "Intersection between client 0 and client 3: 0\n",
      "Intersection between client 1 and client 2: 0\n",
      "Intersection between client 1 and client 3: 0\n",
      "Intersection between client 2 and client 3: 0\n"
     ]
    }
   ],
   "source": [
    "# Intersecting images\n",
    "# len(set(client_dfs[2][\"Image Index\"].unique()).intersection(set(client_dfs[1][\"Image Index\"].unique())))\n",
    "\n",
    "# Check intersection between clients\n",
    "for i in range(n_clients):\n",
    "    for j in range(i + 1, n_clients):\n",
    "        print(f\"Intersection between client {i} and client {j}: {len(set(client_dfs[i]['Image Index'].unique()).intersection(set(client_dfs[j]['Image Index'].unique())))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analyzer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
